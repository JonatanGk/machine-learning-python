{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "db412e85",
   "metadata": {},
   "source": [
    "# Construyendo modelos con PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb2c2e0e",
   "metadata": {},
   "source": [
    "## `torch.nn.Module` y `torch.nn.Parameter`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "`torch.nn.Module` es la clase base para cualquier red neuronal en PyTorch. Cualquier clase que herede de `torch.nn.Module` debe implementar el método `forward`. El método `forward` es el que define cómo se calcula la salida de la red neuronal.\n",
    "\n",
    "Cualquier objeto de tipo `torch.nn.Module` registra todos los parámetros de la red neuronal (los pesos y los sesgos). Estos parámetros son objetos de tipo `torch.nn.Parameter`, que es una subclase de `torch.Tensor`. Los parámetros se pueden acceder a través del método `parameters()` de la clase `Module`.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación se muestra un ejemplo de cómo definir una red neuronal muy básica en PyTorch. Esta red consta de dos capas lineales y una función de activación ReLU entre ellas. En ella podemos ver la estructura básica de una red neuronal en PyTorch, con un método `__init__()` que define las capas y otros componentes de la red, y un método `forward()` donde se realiza la computación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model:\n",
      "TinyModel(\n",
      "  (linear1): Linear(in_features=100, out_features=200, bias=True)\n",
      "  (activation): ReLU()\n",
      "  (linear2): Linear(in_features=200, out_features=10, bias=True)\n",
      "  (softmax): Softmax(dim=None)\n",
      ")\n",
      "\n",
      "\n",
      "Just one layer:\n",
      "Linear(in_features=200, out_features=10, bias=True)\n",
      "\n",
      "\n",
      "Model params:\n",
      "Parameter containing:\n",
      "tensor([[-0.0329,  0.0004,  0.0033,  ..., -0.0296,  0.0088, -0.0540],\n",
      "        [ 0.0028,  0.0299, -0.0915,  ...,  0.0280,  0.0159,  0.0241],\n",
      "        [ 0.0849, -0.0265,  0.0135,  ...,  0.0054, -0.0537,  0.0781],\n",
      "        ...,\n",
      "        [ 0.0962, -0.0228,  0.0483,  ..., -0.0508,  0.0863,  0.0836],\n",
      "        [ 0.0817,  0.0024, -0.0186,  ..., -0.0605,  0.0609,  0.0930],\n",
      "        [ 0.0377,  0.0560,  0.0769,  ..., -0.0957, -0.0265,  0.0938]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.0781,  0.0995, -0.0125, -0.0679, -0.0547,  0.0714, -0.0814,  0.0777,\n",
      "        -0.0235,  0.0665,  0.0734,  0.0367,  0.0119,  0.0529, -0.0481, -0.0919,\n",
      "         0.0495,  0.0223,  0.0138,  0.0812,  0.0554, -0.0528, -0.0677,  0.0478,\n",
      "        -0.0066,  0.0580,  0.0476, -0.0063,  0.0784, -0.0766, -0.0377, -0.0481,\n",
      "        -0.0426,  0.0223,  0.0662, -0.0502,  0.0540,  0.0719,  0.0349, -0.0778,\n",
      "         0.0886, -0.0414,  0.0688,  0.0590,  0.0698,  0.0814, -0.0077, -0.0701,\n",
      "        -0.0298,  0.0002,  0.0753,  0.0858,  0.0321, -0.0054,  0.0426, -0.0713,\n",
      "        -0.0253, -0.0026,  0.0983, -0.0754,  0.0215, -0.0541,  0.0808, -0.0923,\n",
      "        -0.0519, -0.0398, -0.0175, -0.0736,  0.0688, -0.0315,  0.0589,  0.0554,\n",
      "         0.0330,  0.0915, -0.0204, -0.0431,  0.0010,  0.0079,  0.0923, -0.0016,\n",
      "        -0.0449, -0.0084, -0.0955, -0.0074,  0.0705,  0.0323, -0.0840,  0.0708,\n",
      "        -0.0881, -0.0672, -0.0025,  0.0208, -0.0171, -0.0759, -0.0194, -0.0523,\n",
      "        -0.0581,  0.0857, -0.0371,  0.0379, -0.0843,  0.0259,  0.0772, -0.0087,\n",
      "         0.0019, -0.0852, -0.0203, -0.0286, -0.0429,  0.0726,  0.0160, -0.0473,\n",
      "         0.0795,  0.0610,  0.0075,  0.0928, -0.0784, -0.0706,  0.0484,  0.0420,\n",
      "         0.0830,  0.0049, -0.0324, -0.0760,  0.0036,  0.0514,  0.0333,  0.0132,\n",
      "        -0.0773,  0.0972, -0.0406, -0.0007,  0.0140,  0.0400,  0.0897,  0.0866,\n",
      "        -0.0096, -0.0897, -0.0766, -0.0712, -0.0960, -0.0824,  0.0017, -0.0163,\n",
      "         0.0790, -0.0898,  0.0794, -0.0754,  0.0008,  0.0296,  0.0277, -0.0339,\n",
      "         0.0760, -0.0187, -0.0956,  0.0068,  0.0986, -0.0626, -0.0568, -0.0180,\n",
      "         0.0632,  0.0273,  0.0227,  0.0242, -0.0245,  0.0951, -0.0267, -0.0785,\n",
      "         0.0874, -0.0980, -0.0456,  0.0672,  0.0263, -0.0700, -0.0679,  0.0822,\n",
      "         0.0690,  0.0131, -0.0262,  0.0823, -0.0953,  0.0588, -0.0006,  0.0014,\n",
      "         0.0930, -0.0520,  0.0849, -0.0877, -0.0779,  0.0593,  0.0635, -0.0498,\n",
      "        -0.0414, -0.0780, -0.0237,  0.0226,  0.0437,  0.0289, -0.0524, -0.0764],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0678, -0.0447,  0.0511,  ..., -0.0256, -0.0569,  0.0076],\n",
      "        [ 0.0646, -0.0022, -0.0233,  ..., -0.0439, -0.0680, -0.0631],\n",
      "        [ 0.0562,  0.0246,  0.0560,  ...,  0.0469,  0.0648,  0.0613],\n",
      "        ...,\n",
      "        [ 0.0236, -0.0022, -0.0564,  ...,  0.0309,  0.0167, -0.0421],\n",
      "        [ 0.0154, -0.0196,  0.0373,  ..., -0.0321,  0.0481,  0.0491],\n",
      "        [ 0.0229, -0.0536,  0.0555,  ...,  0.0146,  0.0523,  0.0629]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.0228,  0.0096, -0.0336,  0.0315,  0.0022, -0.0598, -0.0021, -0.0103,\n",
      "        -0.0256,  0.0081], requires_grad=True)\n",
      "\n",
      "\n",
      "Layer params:\n",
      "Parameter containing:\n",
      "tensor([[-0.0678, -0.0447,  0.0511,  ..., -0.0256, -0.0569,  0.0076],\n",
      "        [ 0.0646, -0.0022, -0.0233,  ..., -0.0439, -0.0680, -0.0631],\n",
      "        [ 0.0562,  0.0246,  0.0560,  ...,  0.0469,  0.0648,  0.0613],\n",
      "        ...,\n",
      "        [ 0.0236, -0.0022, -0.0564,  ...,  0.0309,  0.0167, -0.0421],\n",
      "        [ 0.0154, -0.0196,  0.0373,  ..., -0.0321,  0.0481,  0.0491],\n",
      "        [ 0.0229, -0.0536,  0.0555,  ...,  0.0146,  0.0523,  0.0629]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.0228,  0.0096, -0.0336,  0.0315,  0.0022, -0.0598, -0.0021, -0.0103,\n",
      "        -0.0256,  0.0081], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "class TinyModel(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear1 = torch.nn.Linear(100, 200) # Capa de entrada\n",
    "        self.activation = torch.nn.ReLU() # Función de activación\n",
    "        self.linear2 = torch.nn.Linear(200, 10) # Capa de salida\n",
    "        self.softmax = torch.nn.Softmax() # Función de salida\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.linear1(x) \n",
    "        x = self.activation(x)\n",
    "        x = self.linear2(x)\n",
    "        x = self.softmax(x)\n",
    "        return x\n",
    "\n",
    "tinymodel = TinyModel()\n",
    "\n",
    "print('The model:')\n",
    "print(tinymodel)\n",
    "\n",
    "print('\\n\\nJust one layer:')\n",
    "print(tinymodel.linear2)\n",
    "\n",
    "print('\\n\\nModel params:')\n",
    "for param in tinymodel.parameters():\n",
    "    print(param)\n",
    "\n",
    "print('\\n\\nLayer params:')\n",
    "for param in tinymodel.linear2.parameters():\n",
    "    print(param)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tipos de capas en PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Capas lineales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El tipo más básico de capa de red neuronal es una capa *lineal* o *totalmente conectada*. Esta es una capa en la que cada entrada influye en cada salida de la capa en un grado especificado por los pesos de la capa. Si un modelo tiene *m* entradas y *n* salidas, los pesos serán una matriz *m* x *n*.\n",
    "\n",
    "Se llama *lineal* porque la salida de la capa es una combinación lineal de las entradas $y=Wx+b$, donde $W$ es la matriz de pesos, $x$ es el vector de entradas y $b$ es el vector de sesgos.\n",
    "\n",
    "Si tenemos 3 entradas $x_1$, $x_2$ y $x_3$ y 2 salidas $y_1$ y $y_2$, la salida de la capa será:\n",
    "\n",
    "$$\\begin{bmatrix} y_1 \\\\ y_2 \\end{bmatrix} = \\begin{bmatrix} w_{11} & w_{12} & w_{13} \\\\ w_{21} & w_{22} & w_{23} \\end{bmatrix} \\begin{bmatrix} x_1 \\\\ x_2 \\\\ x_3 \\end{bmatrix}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parámetros de la capa (pesos y sesgos):\n",
      "Parameter containing:\n",
      "tensor([[-0.2069,  0.2911, -0.0554],\n",
      "        [-0.3530, -0.0932,  0.4839]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.5717, -0.4867], requires_grad=True)\n",
      "\n",
      "\n",
      "Pesos: Parameter containing:\n",
      "tensor([[-0.2069,  0.2911, -0.0554],\n",
      "        [-0.3530, -0.0932,  0.4839]], requires_grad=True)\n",
      "\n",
      "\n",
      "Sesgos: Parameter containing:\n",
      "tensor([-0.5717, -0.4867], requires_grad=True)\n",
      "\n",
      "\n",
      "Input: tensor([[0.4343, 0.9277, 0.8893]])\n",
      "\n",
      "\n",
      "Output:\n",
      "tensor([[-0.4408, -0.2962]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "lin = torch.nn.Linear(3, 2) # 3 entradas, 2 salidas\n",
    "\n",
    "print('Parámetros de la capa (pesos y sesgos):')\n",
    "for param in lin.parameters():\n",
    "    print(param)\n",
    "\n",
    "# Lo mismo accediendo directamente a cada atributo:\n",
    "print('\\n\\nPesos:', lin.weight)\n",
    "print('\\n\\nSesgos:', lin.bias)\n",
    "\n",
    "x = torch.rand(1, 3) # Tensor de entrada de 1x3\n",
    "print('\\n\\nInput:', x)\n",
    "\n",
    "y = lin(x)\n",
    "print('\\n\\nOutput:')\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver que `lin.weight` contiene la matriz de pesos y que `lin.bias` contiene el vector de sesgos, siendo ambos de tipo `Parameter`.\n",
    "\n",
    "`Parameter` es una subclase de `Tensor` que se utiliza para indicar que un tensor es un parámetro de una red neuronal y, por lo tanto, debe registrar los gradientes por el módulo de autograd de PyTorch. Esto es importante para que PyTorch pueda calcular los gradientes de los parámetros durante el entrenamiento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fuentes\n",
    "\n",
    "- https://pytorch.org/tutorials/beginner/introyt/modelsyt_tutorial.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
